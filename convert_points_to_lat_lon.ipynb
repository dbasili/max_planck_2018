{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAKE IMPORTS\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import geoio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointTransposer():\n",
    "    \n",
    "    def __init__(self, map_p, pic_p, points_p, previous_secs, sub_size, point_pairs=np.array([False])):\n",
    "        ''' Constructor\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        map_p: str\n",
    "            path to the large map (a geotiff) you want the points to be put onto\n",
    "        pic_p: str\n",
    "            path to slide from video of animals that we are using to create transformation matrix\n",
    "        points_p: str\n",
    "            path to list of animal locations (in pixels) from video\n",
    "        previous_secs: int\n",
    "            number of previous seconds that the drone was recording video before video of interest started\n",
    "        sub_size: int\n",
    "            diameter of the subsection square of the large map that you want to examine to compare to video slides\n",
    "        point_pairs: numpy array\n",
    "            optional list of corresponding points between the two pictures that have been identified manually\n",
    "            each pair of points has [[first picture point], [second picture point]]\n",
    "            ex: [[[1,2], [3,4]],\n",
    "                 [[5,6], [7,8]]\n",
    "                 [[9,10], [11,12]]] '''\n",
    "        \n",
    "        #read in geotiff\n",
    "        self.geo_img = geoio.GeoImage(map_p)\n",
    "\n",
    "        #read in points locating where animals are in video\n",
    "        self.csv = False #keeps track of if points come in .csv format or .npy format\n",
    "        if 'csv' in points_p:\n",
    "            self.points_file = pd.read_csv(points_p)\n",
    "            self.points_file = self.points_file.values\n",
    "            self.csv = True\n",
    "        elif 'npy' in points_p:\n",
    "            self.points_file = np.load(points_p)\n",
    "        else:\n",
    "            print('not recognized format for file containing animal points.')\n",
    "                \n",
    "        #read in pictures in greyscale and load other variables\n",
    "        self.xPixel, self.yPixel = 30000, 10000        \n",
    "        full_region = self.get_tiff_pic(map_p)\n",
    "        surround_region = full_region[int(self.yPixel-sub_size/2):int(self.yPixel+sub_size/2), \n",
    "                                      int(self.xPixel-sub_size/2):int(self.xPixel+sub_size/2)]\n",
    "        specific_pic = cv2.imread(pic_p,0)\n",
    "        self.pic_height = np.size(specific_pic,0)\n",
    "        self.sub_size = sub_size\n",
    "\n",
    "        #make transformation matrix to convert points from video image to points in terms of pixels in large map\n",
    "        self.matrix = self.get_transformation_matrix(specific_pic, surround_region, point_pairs)\n",
    "    \n",
    "    \n",
    "    def get_slide_points_npy(self, points_file, slide_number, pic_height):\n",
    "        ''' Gets an array of points marking each animal corresponding to the picture being used\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        points_path: str\n",
    "            path to .npy file on computer containing arrays of points locating the animals on each slide of video\n",
    "        slide_number: int\n",
    "            number of slides after first slide in video being used (starting at 0 for first slide)\n",
    "        pic_height: int\n",
    "            number of rows of pixels in each picture of the animals in video\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.float32 containing a list of tuples with each point value in pixels '''\n",
    "        \n",
    "        #points of one slide - slide_number references csv data, there are 3 tracks and 6 frames for every csv data point\n",
    "        slide_points = points_file[slide_number]\n",
    "\n",
    "        #adjust points to make them correct due to weird formatting of input\n",
    "        adjusted_points = np.zeros(slide_points.shape)\n",
    "        adjusted_points = [[point[1],pic_height - point[0]]  for point in slide_points]\n",
    "\n",
    "        return np.float32([adjusted_points])\n",
    "    \n",
    "    \n",
    "    def get_slide_points_csv(self, points_file, slide_number, pic_height):\n",
    "        ''' Gets an array of points marking each animal corresponding to the picture being used\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        points_file: \n",
    "            path to .npy file on computer containing arrays of points locating the animals on each slide of video\n",
    "        slide_number: int\n",
    "            number of slides after first slide in video being used (starting at 0 for first slide)\n",
    "        pic_height: int\n",
    "            number of rows of pixels in each picture of the animals in video\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.float32 containing a list of tuples with each point value in pixels '''\n",
    "        \n",
    "        #points of one slide - slide_number references csv data, there are 3 tracks and 6 frames for every csv data point\n",
    "        slide_points = points_file[slide_number]\n",
    "        if slide_number == 0:\n",
    "            slide_points = points_file[1]\n",
    "\n",
    "        #adjust points to make them correct due to weird formatting of input\n",
    "        adjusted_points = np.zeros((int((len(slide_points) - 1)/2),2))\n",
    "\n",
    "        for i in range(int((len(slide_points)-1)/2)):\n",
    "            adjusted_points[i] = [slide_points[2*i+1], pic_height - slide_points[2+2*i]]\n",
    "\n",
    "        return np.float32([adjusted_points])\n",
    "\n",
    "    \n",
    "    def get_track_points_csv(self, points_file, track_number, pic_height): #may need more editing\n",
    "        ''' Gets an array of points marking each animal corresponding to the picture being used\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        points_path: str\n",
    "            path to .npy file on computer containing arrays of points locating the animals on each slide of video\n",
    "        track_number: int\n",
    "            number of track you want to examine\n",
    "        pic_height: int\n",
    "            number of rows of pixels in each picture of the animals in video\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.float32 containing a list of tuples with each point value in pixels '''\n",
    "        \n",
    "        #points of one slide - slide_number references csv data, there are 3 tracks and 6 frames for every csv data point\n",
    "        track_points = points_file[:, track_number*2:track_number*2+2]\n",
    "\n",
    "        print(track_points)\n",
    "        \n",
    "        #adjust points to make them correct due to weird formatting of input\n",
    "        adjusted_points = np.zeros(track_points.shape)\n",
    "        for i in range(len(track_points)):\n",
    "            adjusted_points[i] = [track_points[i][0], pic_height - track_points[i][1]]\n",
    "\n",
    "        return np.float32([adjusted_points])\n",
    "\n",
    "\n",
    "    def get_starting_point(self, csv_file, previous_seconds):\n",
    "        ''' Get the row number of the first data point from csv file that should be used, since there are data points in\n",
    "        the csv file that are irrelevant to the data we care about\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        csv_file: str\n",
    "            path to the csv file with latitude/longitude and other data points recorded many times each second that the\n",
    "            drone was in the air\n",
    "        previous_seconds: int\n",
    "            the number of previous seconds the drone had been in the air recording before it started recording data we\n",
    "            care about (can be found in other csv file with info about all drone flights)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        int: the first row number in csv file that we should use '''\n",
    "\n",
    "        DATA_POINTS_PER_SEC = 10 #number of data points in csv file taken per second\n",
    "\n",
    "        #get column for the 'isVideo' data column in csv file\n",
    "        isVideo_col = csv_file['isVideo']\n",
    "\n",
    "        #set video_start to when isVideo first turns to 1\n",
    "        video_start = 0\n",
    "        for i in range(0, len(isVideo_col)):\n",
    "            if isVideo_col[i] == 1:\n",
    "                video_start = i\n",
    "                break\n",
    "            if i >= len(isVideo_col) - 1:\n",
    "                print(\"warning: isVideo column in csv file does not have any '1' values\")\n",
    "\n",
    "        #return starting frame\n",
    "        return previous_seconds*DATA_POINTS_PER_SEC + video_start\n",
    "\n",
    "\n",
    "    def get_center_point(self, csv_file, starting_point, data_point_number, geo_img, coord_sys1=4326, coord_sys2=32637):\n",
    "        ''' Returns latitude and longitude point of center of specified video frame\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        csv_file: str\n",
    "            path to the csv file with latitude/longitude and other data points recorded many times each second that the\n",
    "            drone was in the air\n",
    "        starting_point: int\n",
    "            the first row number of csv file that contains data relevant to our video\n",
    "        data_point-number: int\n",
    "            the number of rows below starting_point where our data is\n",
    "        geo_img: GeoImage (?)\n",
    "            the geotiff image having been read in using geoio.GeoImage\n",
    "        coord_sys1: int\n",
    "            EPSG number of the coordinate system the lat/lon coordinates from csv file come in - csv is EPSG4326\n",
    "        coord_sys2: int\n",
    "            EPSG number of the coordinate system the lat/lon coordinates of map are in - geotiff is EPSG32637\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        array: [xPixel, yPixel] '''\n",
    "         \n",
    "        from pyproj import Proj, transform\n",
    "\n",
    "        #get latitude and longitude\n",
    "        lat, lon = csv_file.loc[starting_point+data_point_number, 'latitude':'longitude'] #returns (lat, lon)\n",
    "\n",
    "        #return coordinates in correct system\n",
    "        inProj = Proj(init='epsg:'+str(coord_sys1))\n",
    "        outProj = Proj(init='epsg:'+str(coord_sys2))\n",
    "        lon, lat = transform(inProj,outProj,lon,lat)\n",
    "\n",
    "        #convert to pixels\n",
    "        return geo_img.proj_to_raster(lon, lat)\n",
    "\n",
    "\n",
    "    def get_tiff_pic(self, map_path):\n",
    "        ''' Get greyscale image from geotiff file\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        map_path: str\n",
    "            path to geotiff file in computer\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        array (?) in same format as cv2.imread() '''\n",
    "        from osgeo import gdal\n",
    "\n",
    "        gdal.UseExceptions()\n",
    "\n",
    "        #return array\n",
    "        ds = gdal.Open(map_path)\n",
    "        rb = ds.GetRasterBand(1)\n",
    "        return rb.ReadAsArray()\n",
    "\n",
    "\n",
    "    def filter_matches(self, kp1, kp2, matches, ratio = 0.75):\n",
    "        ''' For aid in getting transformation matrix, filter matches where descriptors aren't close enough\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        kp1: array\n",
    "            array of key points in first picture\n",
    "        kp2: array\n",
    "            array of key points in second picture\n",
    "        matches: array\n",
    "            array of keypoints that are matches\n",
    "        ratio: float\n",
    "            used to filter out matches based on how close they match\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.float32 array: [points from first picture, corresponding points from second picture] '''\n",
    "\n",
    "        # Sort matches in order of their distance\n",
    "        matches = sorted(matches, key = lambda x:x[0].distance)\n",
    "\n",
    "        #filter out matches based on how closely they match and keep top N matches\n",
    "        good = []\n",
    "        counter = 0\n",
    "        N_MATCHES = 15\n",
    "        for m in matches:\n",
    "            if len(m) == 2 and m[0].distance < m[1].distance * ratio:\n",
    "                m = m[0]\n",
    "                good.append( m )\n",
    "                counter += 1\n",
    "            if counter>=N_MATCHES:\n",
    "                break\n",
    "\n",
    "        print(\"Number of matches found = %d\" % len(good))\n",
    "\n",
    "        #convert to correct format\n",
    "        src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "        dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "\n",
    "        return src_pts, dst_pts\n",
    "\n",
    "\n",
    "    def get_transformation_matrix(self, specific_pic, full_region, points_list=np.array([False])):\n",
    "        ''' Returns transformation matrix to convert points from animal footage to corret pixels in full picture\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        specific_pic: numpy array\n",
    "            array of greyscale points for animal footage picture\n",
    "        full_region:  numpy array\n",
    "            array of greyscale points for subsection of full map that includes at least part of animal footage picture\n",
    "        points_list: numpy array\n",
    "            optional list of corresponding points between the two pictures that have been identified manuall\n",
    "            each pair of point has [[first picture point], [second picture point]]\n",
    "            ex: [[[1,2], [3,4]],\n",
    "                 [[5,6], [7,8]]\n",
    "                 [[9,10], [11,12]]]\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        array: 3x3 array of floats as the transformation matrix '''\n",
    "\n",
    "        print('finding transformation matrix...')\n",
    "\n",
    "        if points_list.any() == False: #if the person has not sent in their own set of points\n",
    "\n",
    "            #can adjust parameters and which detector to use to adjust types of detected features\n",
    "            orb = cv2.ORB_create(nfeatures=100000, scoreType=cv2.ORB_FAST_SCORE)        \n",
    "            matcher = cv2.BFMatcher(cv2.NORM_L2)\n",
    "\n",
    "            #detect key points in each image\n",
    "            kp1, desc1 = orb.detectAndCompute(specific_pic, None)\n",
    "            kp2, desc2 = orb.detectAndCompute(full_region, None)\n",
    "\n",
    "            #match key points between images\n",
    "            raw_matches = matcher.knnMatch(desc1, trainDescriptors = desc2, k = 2) #2\n",
    "            src_pts, dst_pts = self.filter_matches(kp1, kp2, raw_matches)\n",
    "\n",
    "            #return mask\n",
    "            return cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)[0]\n",
    "\n",
    "        else: #if the person has sent in their own set of points\n",
    "\n",
    "            #put lists of points from both pictures in correct format\n",
    "            src_pts = np.float32([ pair[0] for pair in points_list ]).reshape(-1,1,2)\n",
    "            dst_pts = np.float32([ pair[1] for pair in points_list ]).reshape(-1,1,2)\n",
    "\n",
    "            #return mask\n",
    "            return cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)[0]\n",
    "    \n",
    "    \n",
    "    def get_points(self, slide_number, folder, type='slide'):\n",
    "        ''' Put points from one slide in animal footage into csv file and saves it in required folder\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        slide_number: int\n",
    "            if type == slide, the time (in 10ths of seconds) that the frame of interest appears since the video started\n",
    "            if type == track, the number of the track to use\n",
    "        folder: str\n",
    "            name of folder to put csv file into\n",
    "        type: str\n",
    "            'slide' if you want to get points from one slide, 'track' to get points from a track\n",
    "        '''\n",
    "        \n",
    "        #get xy pixel points identifying animals in video image\n",
    "        if type == 'slide':\n",
    "            if self.csv == False:\n",
    "                pts = self.get_slide_points(self.points_file, slide_number*3, self.pic_height)\n",
    "            elif self.csv == True:\n",
    "                pts = self.get_slide_points_csv(self.points_file, slide_number*3, self.pic_height)\n",
    "        else:\n",
    "            pts = self.get_track_points_csv(self.points_file, slide_number, self.pic_height)\n",
    "\n",
    "        #get points of animals in terms of pixels of map subsection\n",
    "        transformation = cv2.perspectiveTransform(pts,self.matrix)\n",
    "\n",
    "        #get points in terms of large map\n",
    "        x_increase = int(self.xPixel - self.sub_size/2)#180 #amount to add to x value to get x in terms of entire map\n",
    "        y_increase = int(self.yPixel - self.sub_size/2)#145\n",
    "        map_view_points = np.zeros(transformation[0].shape)\n",
    "        map_view_points = [(point[0]+x_increase, point[1]+y_increase) for point in transformation[0]]\n",
    "\n",
    "        #get points in terms of lat/lon values\n",
    "        lon_lat_final = np.zeros((len(map_view_points), 2))\n",
    "        lon_lat_final = [(self.geo_img.raster_to_proj(map_view_points[i][0], map_view_points[i][1]))\n",
    "                         for i in range(0, len(map_view_points))]\n",
    "\n",
    "        #output values to a csv\n",
    "        np.savetxt(folder+'/'+type+str(slide_number)+\".csv\",lon_lat_final,delimiter=\",\")\n",
    "    \n",
    "    \n",
    "    def get_all_points(self, folder):\n",
    "        ''' Transform points in csv file into latitude/longitude coordinates, puts csv file into required folder\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        folder: str\n",
    "            name of folder to put csv file into\n",
    "        '''\n",
    "        \n",
    "        #get all points from csv file\n",
    "        good_points = np.zeros((int(len(self.points_file) - 1), int((len(self.points_file[0]) - 1)/2),2))\n",
    "        for i in range(len(self.points_file)-1):\n",
    "            good_points[i] = self.get_slide_points_csv(self.points_file, i, self.pic_height)\n",
    "        \n",
    "        #get transformation of points\n",
    "        transformation = cv2.perspectiveTransform(good_points, self.matrix)\n",
    "        \n",
    "        #get points in terms of larger map\n",
    "        x_increase = int(self.xPixel - self.sub_size/2)\n",
    "        y_increase = int(self.yPixel - self.sub_size/2)\n",
    "        map_view_points = np.zeros(good_points.shape)\n",
    "        for i in range(len(good_points)):\n",
    "            map_view_points[i] = [(point[0]+x_increase, point[1]+y_increase) for point in transformation[i]]\n",
    "        \n",
    "        #get points in terms of lat/lon values\n",
    "        lon_lat_final = np.zeros(good_points.shape)\n",
    "        for i in range(len(good_points)):\n",
    "            lon_lat_final[i] = [(self.geo_img.raster_to_proj(map_view_points[i][j][0], map_view_points[i][j][1]))\n",
    "                             for j in range(0, len(map_view_points[i]))]\n",
    "        \n",
    "        #create matrix to put lat/lon values in\n",
    "        positions = np.empty((len(map_view_points), len(map_view_points[0])*2))\n",
    "        for i in range(0, len(positions)):\n",
    "            for j in range(0, len(positions[0])):\n",
    "                if j % 2 == 0:\n",
    "                    positions[i][j] = lon_lat_final[i][int(j/2)][0]\n",
    "                else:\n",
    "                    positions[i][j] = lon_lat_final[i][int(j/2)][1]\n",
    "        \n",
    "        #column labels for matrix with lat/lon values\n",
    "        column_names = []\n",
    "        for ind in range(len(map_view_points[0])*2):\n",
    "            xy = ''\n",
    "            if ind % 2 == 0:\n",
    "                xy = 'lon'\n",
    "            else:\n",
    "                xy = 'lat'\n",
    "            column_names.append('track_' + str(ind//2) + '_' + xy)\n",
    "        \n",
    "        #output values to a csv\n",
    "        positions_df = pd.DataFrame(positions, columns=column_names)\n",
    "        positions_df.to_csv(folder+'/all_points.csv')\n",
    "\n",
    "        print('all_points.csv created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transposer():\n",
    "    \n",
    "    def __init__(self, transposer_start, transposer_end, input_length):\n",
    "        ''' transpose points to latitude/longitude coordinates more accurately than before. Pass in two csv files with \n",
    "        lat/lon locations, one based on data from beginning of video, one based on the end of the video. Take weighted \n",
    "        averages of point locations to make lat/lon locations of points at the beginning of the video be based more on\n",
    "        the transformation matrix from the beginning of the video, and the locations at the end based more on the \n",
    "        transformation matrix from the end of the video.\n",
    "        \n",
    "        input_length = number of latitude/longitude points recorded for drone video\n",
    "        '''\n",
    "        self.transposer_start, self.transposer_end = transposer_start, transposer_end\n",
    "        self.input_length = input_length\n",
    "    \n",
    "    def get_points(self, slide_number, folder, type='slide'):\n",
    "        csv_p = folder+'/'+type+str(slide_number)+\".csv\"\n",
    "        fraction = slide_number / self.input_length\n",
    "        \n",
    "        #get first points\n",
    "        self.transposer_start.get_points(slide_number, folder,type=type)\n",
    "        csv_start = pd.read_csv(csv_p).values\n",
    "        \n",
    "        #get last points\n",
    "        self.transposer_end.get_points(slide_number, folder, type=type)\n",
    "        csv_end = pd.read_csv(csv_p).values\n",
    "        \n",
    "        #take averages\n",
    "        final_result = np.zeros(csv_start.shape)\n",
    "        for i in range(len(csv_start)):\n",
    "            final_result[i] = [csv_start[i][0]*fraction + csv_end[i][0]*(1-fraction), \n",
    "                               csv_start[i][1]*fraction + csv_end[i][1]*(1-fraction)]\n",
    "        \n",
    "        np.savetxt(csv_p,final_result,delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding transformation matrix...\n"
     ]
    }
   ],
   "source": [
    "map_p = '/Users/dbasili/csv_files_airstrip2/Geotiffs/riverside005_011_merge_transparent_mosaic_group1.tif'\n",
    "pic_p = '/Users/dbasili/csv_files_airstrip2/frames/APR08_2018_C_DJI_0010_2.jpg' #change number when necessary\n",
    "csv_p = '/Users/dbasili/csv_files_airstrip2/2018-04-08_8-26-33_Standard.csv'\n",
    "folder = '/Users/dbasili/csv_files_airstrip2'\n",
    "#points_p = '/Users/dbasili/koger_drive/positions.npy' #points of animals on one slide\n",
    "points_p = '/Users/dbasili/csv_files_airstrip2/APR08_2018_C_DJI_0010-tracks.csv'\n",
    "slide_num = 1636                                         #number after starting_number to get data from\n",
    "previous_secs = 328+328+328+240+328+328+328+317+327 #600 #602 #655   #in csv file before getting to video of interest\n",
    "subsection_size = 6000                                #size of full map subsection\n",
    "\n",
    "#[244,874]=newpic, [3452,956]=originalpic\n",
    "y_1636 = 874-956\n",
    "x_1636 = 244-3452\n",
    "\n",
    "point_pairs0 = np.float32([[[1814,548], [640,2821]],\n",
    "                           [[1605,617], [717,3068]],\n",
    "                           [[994,1016], [1183,3797]],\n",
    "                           [[534,938], [1098,4352]],\n",
    "                           [[245,871], [1014,4727]],\n",
    "                           [[3071,470], [547,1391]],\n",
    "                           [[2161,1293], [1499,2415]],\n",
    "                           [[3639,1269], [1452,713]],\n",
    "                           [[2940,1434], [1649,1503]],\n",
    "                           [[3441,1101], [1261,947]]])\n",
    "\n",
    "point_pairs1636 = np.float32([[[3452+x_1636,954+y_1636],  [1015,4728]],\n",
    "                              [[1806+x_1636,4996+y_1636], [3224,1663]],\n",
    "                              [[2300+x_1636,1626+y_1636], [1807,6066]],\n",
    "                              [[1422+x_1636,867+y_1636],  [934,7071]],\n",
    "                              [[1584+x_1636,459+y_1636],  [473,6889]],\n",
    "                              [[2110+x_1636,552+y_1636],  [578,6292]]])\n",
    "\n",
    "transposer=PointTransposer(map_p,pic_p,points_p,previous_secs,subsection_size,point_pairs=point_pairs0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding transformation matrix...\n",
      "finding transformation matrix...\n"
     ]
    }
   ],
   "source": [
    "transposer0=PointTransposer(map_p,pic_p,points_p,previous_secs,subsection_size,point_pairs=point_pairs0)\n",
    "transposer1636=PointTransposer(map_p,pic_p,points_p,previous_secs,subsection_size,point_pairs=point_pairs1636)\n",
    "video_length = 3272\n",
    "\n",
    "final_transposer = Transposer(transposer0,transposer1636,video_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[           nan            nan]\n",
      " [  442.65307617  2433.5378418 ]\n",
      " [  443.54528809  2433.24023438]\n",
      " ...\n",
      " [ 1108.29467773 -1734.64013672]\n",
      " [ 1108.26623535 -1735.06445312]\n",
      " [ 1108.48583984 -1734.66845703]]\n",
      "[[           nan            nan]\n",
      " [  904.56005859  2444.3059082 ]\n",
      " [  904.60339355  2443.94555664]\n",
      " ...\n",
      " [ 1177.88024902 -1817.77270508]\n",
      " [ 1178.60742188 -1817.64318848]\n",
      " [ 1178.46557617 -1816.58056641]]\n"
     ]
    }
   ],
   "source": [
    "transposer.get_points(0, folder)\n",
    "transposer.get_points(2419, folder)\n",
    "transposer.get_points(3272, folder)\n",
    "transposer.get_points(1, folder,type='track')\n",
    "transposer.get_points(2, folder,type='track')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_transposer.get_points(0, folder)\n",
    "final_transposer.get_points(2419, folder)\n",
    "final_transposer.get_points(3272, folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_points.csv created\n"
     ]
    }
   ],
   "source": [
    "transposer.get_all_points(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
